# Machine Learning Classifier

## Como executar os c√≥digos? üßë‚Äçüíª
Crie um ambiente virtual Python:
```bash
python3 -m venv /path/to/new/virtual/environment
```

Ative o ambiente virtual: 
```bash
source /path/to/new/virtual/environment/bin/activate
```

Instale as depend√™ncias com ``deploy/requeriments.txt``:
```bash
pip install requeriments.txt
```

Adicione o ambiente virtual ao "kerneis" do Jupyter Notebook (Jupyter Lab):
```bash
python3 -m ipykernel install --name environment
```

Executada a √∫ltima instru√ß√£o o ambiente virtual dever√° aparecer na lista de "kerneis" do Jupyter Notebook (Jupyter Lab), selecione-o e divirta-se! üòÑ
## Introdu√ß√£o
Dentre os algoritmos testados para a resolu√ß√£o do problema a *Regress√£o Log√≠stica* apresentou o melhor resultado. Al√©m deste foram testados os algoritmos *√Årvore de Deci√ß√£o*, *K Nearest Neighbors (KNN)* e *Support Vector Machine (SVM)*. Devido a baixa quantidade de dados *Redes Neurais* foram desconsideradas.

Para uma melhor acompanhamento das etapas desse projeto sugiro a seguinte *timeline* de leitura e/ou execu√ß√£o dos arquivos:
1. ``data_cleaning.ipynb``
2. ``eda.html``
3. ``logistic_regression.ipynb``
4. Diret√≥rio ``deploy``

## An√°lise Explorat√≥ria dos Dados (AED) üìä
Foi realizanda uma AED autom√°tica usando o pacote DataPrep. Ela fornece uma excelente vis√£o geral dos dados. Uma AED mais espec√≠fica √© feita na etapa de prepara√ß√£o dos dados de cada algoritmo. Para visualizar a AED autom√°tica abra no seu navegador o arquivo ``eda.html``.

## Prepara√ß√£o dos Dados
Em geral, diferentes algoritmos possuem diferentes premissas, normalmente, implicando em diferentes m√©todos de prepara√ß√£o de dados para diferentes algoritmos. Neste problema foi usado o algoritmo Regress√£o Log√≠stica, que possue as seguintes particularidades na prepara√ß√£o dos dados:

**Vair√°vel de Sa√≠da Bin√°ria**: A regress√£o log√≠stica √© pensada para a classifica√ß√£o bin√°ria

**Remover o Ru√≠do**: A regress√£o l√≥gistica assume erro zero na vari√°vel de sa√≠da (target), considere remover outliers e poiss√≠veis amostras classificadas err√¥neamente do conjunto de treinamento.

**Distribui√ß√£o Gaussiana**: A regress√£o l√≥gistica √© um algoritmo linear (com uma transforma√ß√£o n√£o linear na sa√≠da). Ele assume uma rela√ß√£o linear entre as vari√°veis de entrada com a vari√°vel de sa√≠da. Transformar as vari√°veis de entrada de modo a expor melhor essa rela√ß√£o pode lever a um modelo mais acurado. Por exemplo, use log, raiz, Box-Cox e outras transforma√ß√µes univariadas para explor melhor essa rela√ß√£o.

**Remover Entradas Correlacionadas**: Assimo como na Regress√£o Linear, o modelo pode overfit se existirem muitas vari√°veis de entradas altamente correlacionadas. Considere calcular a correla√ß√£o entre as vari√°veis de entrada e remover entradas altamente correlacionadas.

**Falhar ao Convergir**: √â poss√≠vel no processo de aprendizagem a falha ao convergir nos valores do coeficientes. Isto pode acontecer se existirem muitas entradas correlacionadas ou se os dados s√£o muito esparsos (por exemplo, muitos zeros nas vari√°veis de entrada).

Mais detalhes podem ser verificados no Jupyter Notebook ``logistic_regression.ipynb``.

## Avalia√ß√£o de Performance
Se tratando de um problema de classific√ß√£o com natureza dos dados desconhecidas achei raso√°vel usar usar a m√©trica *acur√°cia* para avaliar a performance do modelo. O conjunto de teste consiste em uma amostra estratificada de 20% dos dados do conjunto original.

## Deploy do Modelo
O modelo foi colocado em produ√ß√£o atrav√©s de uma API contru√≠da com o *framework* Flask disponibilizada na plataforma Heroku. O *endpoint* para obter as previs√µes do modelo √©: (https://machine-learning-classifier.herokuapp.com/predict)

Para acessar os c√≥digos da API veja: (https://github.com/hagijakobson/machine-learning-classifier-api)

No Jupyter Notebook ``logistic_regression.ipynb`` v√™-se um exemplo de como usar a API. 
